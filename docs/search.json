[
  {
    "objectID": "Teaching.html",
    "href": "Teaching.html",
    "title": "Quanjia Xiao (è‚–æƒçˆ)",
    "section": "",
    "text": "â˜€ï¸\n  ğŸŒ™"
  },
  {
    "objectID": "publications.html#academic-links",
    "href": "publications.html#academic-links",
    "title": "Projects & Publications",
    "section": "Academic Links",
    "text": "Academic Links\n\nğŸ“ Google Scholar Â· ğŸ†” ORCID Â· ğŸ”¬ ResearchGate"
  },
  {
    "objectID": "publications.html#featured-projects",
    "href": "publications.html#featured-projects",
    "title": "Projects & Publications",
    "section": "Featured Projects",
    "text": "Featured Projects\n\n\nWebAgent å¼ºåŒ–å­¦ä¹ å¢å¼º VLM\n\n::: {.tag}VLM::: ::: {.tag}RL::: ::: {.tag}WebAgent::: ::: {.tag}RAG:::\n\nä¸é¦™æ¸¯å¤§å­¦åˆä½œ | 2025.4 â€“ 2025.6\né’ˆå¯¹å°å‹ VLM äº‹å®çŸ¥è¯†ä¸è¶³é—®é¢˜ï¼Œè®¾è®¡ instruction-aware SFT ä¸ Web-Agent å¢å¼ºå­¦ä¹ ï¼Œå®Œæˆå°è§„æ¨¡åŸå‹ã€‚\nKnow-RFT æ¡†æ¶ç‰¹æ€§ï¼š - æŒ‡ä»¤æ„ŸçŸ¥çš„ç›‘ç£å¾®è°ƒ - WebAgent å¼ºåŒ–å­¦ä¹ å¢å¼º - RAG ä¸ Search-R1 ç»“åˆ - åœ¨æœ‰é™æ˜¾å­˜ç¯å¢ƒä¸‹å®ç°å¢é‡è®­ç»ƒä¸æ£€ç´¢å¢å¼º\n\n\näºŒç»´ç‡ƒçƒ§åœºç ”ç©¶\n\n::: {.tag}CNN::: ::: {.tag}Transformer::: ::: {.tag}ViT-UNet::: ::: {.tag}Diffusion Model::: ::: {.tag}PINN:::\n\nä¸è“ç®­èˆªå¤©åˆä½œ | 2024.11 â€“ 2025.3\nç»“åˆå¯†åº¦/æ¸©åº¦åœºæ•°æ®ï¼Œè”åˆ CNN+Transformer è¿›è¡Œç‰©ç†é‡å›å½’ä¸é‡å»ºã€‚\nä¸»è¦æˆæœï¼š - ä»¥ VIT-UNet å»ºæ¨¡ç«ç„°å›¾åƒï¼ŒRMSE â‰ˆ 0.65% - å°è¯•æ‰©æ•£æ¨¡å‹ + PINN æ³¨å…¥ç‰©ç†çº¦æŸæå‡ç¨³å®šæ€§ - ç‰©ç†é‡å›å½’ä¸é‡å»º\n\n\n:::"
  },
  {
    "objectID": "publications.html#research-areas",
    "href": "publications.html#research-areas",
    "title": "Projects & Publications",
    "section": "Research Areas",
    "text": "Research Areas\n\nMy research focuses on the intersection of Large Language Models, Computer Vision, and Reinforcement Learning. Iâ€™m particularly interested in:\n\nVision-Language Models: Enhancing factual knowledge and reasoning capabilities\nAI Agents: Building autonomous agents that can interact with web environments\nScientific Computing: Applying ML to combustion and fluid dynamics problems\nMultimodal Learning: Combining vision, language, and structured data"
  },
  {
    "objectID": "publications.html#papers-technical-notes",
    "href": "publications.html#papers-technical-notes",
    "title": "Projects & Publications",
    "section": "Papers & Technical Notes",
    "text": "Papers & Technical Notes\n\nğŸ“ Coming Soon\nIâ€™m currently working on publishing research papers and technical notes. Check back soon for updates on:\n\nKnow-RFT framework for VLM enhancement\nPhysics-informed neural networks for combustion modeling\nWebAgent reinforcement learning methodologies\n\n\nğŸ“ Google Scholar Â· ğŸ†” ORCID"
  },
  {
    "objectID": "publications.html#skills-technologies",
    "href": "publications.html#skills-technologies",
    "title": "Projects & Publications",
    "section": "Skills & Technologies",
    "text": "Skills & Technologies\n\n\nMachine Learning\n\n::: {.tag}PyTorch::: ::: {.tag}TensorFlow::: ::: {.tag}LLM::: ::: {.tag}RLHF:::\n\n\n\nComputer Vision\n\n::: {.tag}VLM::: ::: {.tag}CNN::: ::: {.tag}Transformer::: ::: {.tag}ViT:::\n\n\n\nMLOps\n\n::: {.tag}LLaMA-Factory::: ::: {.tag}LoRA::: ::: {.tag}QLoRA::: ::: {.tag}RAG:::"
  },
  {
    "objectID": "games.html#section",
    "href": "games.html#section",
    "title": "Mario Game",
    "section": "ğŸ®",
    "text": "ğŸ®"
  },
  {
    "objectID": "games.html#how-to-play",
    "href": "games.html#how-to-play",
    "title": "Mario Game",
    "section": "How to Play",
    "text": "How to Play\n\nğŸ® Controls\n\nDesktop: Press SPACE or Click to jump\nMobile: Tap anywhere on the screen\n\nCollect yellow coins for points, avoid green pipes and brown enemies!\n\n\nğŸ† Tips\n\nTime your jumps carefully to clear obstacles\nCollect coins to boost your score\nDifficulty increases as you progress\nTry to beat your high score!\n\n\n\nHave fun playing! This is a tribute to the classic Super Mario Bros game that has entertained generations of gamers."
  },
  {
    "objectID": "codes.html",
    "href": "codes.html",
    "title": "Quanjia Xiao (è‚–æƒçˆ)",
    "section": "",
    "text": "â˜€ï¸\n  ğŸŒ™"
  },
  {
    "objectID": "books.html",
    "href": "books.html",
    "title": "Quanjia Xiao (è‚–æƒçˆ)",
    "section": "",
    "text": "â˜€ï¸\n  ğŸŒ™"
  },
  {
    "objectID": "about.html#title-about",
    "href": "about.html#title-about",
    "title": "Quanjia Xiao (è‚–æƒçˆ)",
    "section": "title: â€œAboutâ€",
    "text": "title: â€œAboutâ€\nQuanjia Xiaoï¼ˆè‚–æƒçˆï¼‰çš„ä¸ªäººä¸»é¡µã€‚æ›´å¤šä¿¡æ¯è§é¦–é¡µä¸ CV.htmlã€‚"
  },
  {
    "objectID": "blog.html#section",
    "href": "blog.html#section",
    "title": "Blog",
    "section": "ğŸ“",
    "text": "ğŸ“"
  },
  {
    "objectID": "blog.html#recent-posts",
    "href": "blog.html#recent-posts",
    "title": "Blog",
    "section": "Recent Posts",
    "text": "Recent Posts\n\nğŸš€ Understanding Large Language Models\nDate: 2025-01-15\nTags: LLM AI Deep Learning\nIn this post, I explore the architecture and training process of large language models, discussing key components like attention mechanisms, transformer architectures, and the scaling laws that govern their performance.\nRead More â†’\n\n\nğŸ–¼ï¸ Vision-Language Models: A Comprehensive Survey\nDate: 2024-12-20\nTags: VLM Computer Vision Multimodal\nVision-Language Models represent a fascinating intersection of computer vision and natural language processing. This survey covers recent advances in VLM architectures, training strategies, and applications.\nRead More â†’\n\n\nğŸ® Reinforcement Learning for Agent Systems\nDate: 2024-11-10\nTags: RL Agents AI\nExploring how reinforcement learning can be applied to build intelligent agents that learn to interact with complex environments, from games to real-world applications.\nRead More â†’"
  },
  {
    "objectID": "blog.html#topics",
    "href": "blog.html#topics",
    "title": "Blog",
    "section": "Topics",
    "text": "Topics\n\n:: {.tag}#LLM:: :: {.tag}#VLM:: :: {.tag}#RL:: :: {.tag}#Agents:: :: {.tag}#Computer Vision:: :: {.tag}#WebAI::\n\n\nMore posts coming soon! Stay tuned for updates on AI research and development."
  },
  {
    "objectID": "Chinese.html#ä¸ªäººä¿¡æ¯",
    "href": "Chinese.html#ä¸ªäººä¿¡æ¯",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "ä¸ªäººä¿¡æ¯",
    "text": "ä¸ªäººä¿¡æ¯\n\n\nå§“åï¼š è‚–æƒçˆ (Quanjia Xiao)\né‚®ç®±ï¼š xiaoqj@stu.pku.edu.cn\nGitHubï¼š KuroJim"
  },
  {
    "objectID": "Chinese.html#æ•™è‚²èƒŒæ™¯",
    "href": "Chinese.html#æ•™è‚²èƒŒæ™¯",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "æ•™è‚²èƒŒæ™¯",
    "text": "æ•™è‚²èƒŒæ™¯\n\n\n\n::: {.timeline-date}2023.9 â€“ 2026.6::: ::: {.timeline-title}ç¡•å£« Â· å·¥ä¸šè½¯ä»¶::: ::: {.timeline-org}åŒ—äº¬å¤§å­¦:::\næ’åçº¦ 10/65\nä¸»è¦è¯¾ç¨‹ï¼š - å¼ºåŒ–å­¦ä¹ åŸºç¡€ - ç§‘å­¦è®¡ç®— - äººå·¥æ™ºèƒ½ä¸è‡ªä¸»æœºå™¨äºº - å·¥ç¨‹åº”ç”¨è½¯ä»¶å¯¼è®º\n\n\n\n\n::: {.timeline-date}2018.9 â€“ 2022.6::: ::: {.timeline-title}å­¦å£« Â· è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯::: ::: {.timeline-org}ä¸­å—å¤§å­¦:::\nGPA: 3.5/4.0\nä¸»è¦è¯¾ç¨‹ï¼š - æ•°æ®ç»“æ„ä¸ç®—æ³• - è®¡ç®—æœºç½‘ç»œ - è®¡ç®—æœºä½“ç³»ç»“æ„ - æ·±åº¦å­¦ä¹ åŸºç¡€"
  },
  {
    "objectID": "Chinese.html#å·¥ä½œç»å†",
    "href": "Chinese.html#å·¥ä½œç»å†",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "å·¥ä½œç»å†",
    "text": "å·¥ä½œç»å†\n\n\n\n::: {.timeline-date}2022.7 â€“ 2023.6::: ::: {.timeline-title}é‡‘èç§‘æŠ€å·¥ç¨‹å¸ˆï¼ˆå…¨èŒï¼‰::: ::: {.timeline-org}äº¤é€šé“¶è¡Œè½¯ä»¶ä¸­å¿ƒï¼ˆé•¿æ²™ï¼‰:::\n\nè´Ÿè´£é“¶è¡Œå†…éƒ¨ç³»ç»Ÿå‰åç«¯å¼€å‘\nå…šæ€»æ”¯å®£ä¼ å§”å‘˜\nå®£ä¼ ä¸åˆ›æ–°äº‹åŠ¡ç›¸å…³è¡Œæ”¿å·¥ä½œ"
  },
  {
    "objectID": "Chinese.html#å®ä¹ ç»å†",
    "href": "Chinese.html#å®ä¹ ç»å†",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "å®ä¹ ç»å†",
    "text": "å®ä¹ ç»å†\n\n\n\n::: {.timeline-date}2025.6 â€“ è‡³ä»Š::: ::: {.timeline-title}å¤§è¯­è¨€æ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆ::: ::: {.timeline-org}åº¦å°æ»¡ | AI äº’å¨±äº‹ä¸šéƒ¨:::\n\n::: {.tag}LLM::: ::: {.tag}WMT::: ::: {.tag}RAG::: ::: {.tag}RLHF:::\n\nä¸»è¦å·¥ä½œï¼š - WMTï¼š ä½¿ç”¨ LLM å®Œæˆäººç±»æ ‡æ³¨æ•°æ®å®Œå–„ï¼ŒåŸºäº in2x æ£€æµ‹è®­ç»ƒä¸ CFT æ¨¡å‹è¯„åˆ†æå‡ - Trick å®éªŒï¼š åŸºäº VeRL å®ç°ç­–ç•¥æ¨¡å—å¹¶è¿›è¡Œæ¶ˆèå®éªŒï¼Œå¾®è°ƒ Qwen-3.1-7B-base æ¨¡å‹ - æ£€ç´¢/æœå¹¿æ¨ï¼š æ­å»º RAG æ£€ç´¢å¢å¼ºä¸è¯„æµ‹ï¼Œé‡‡ç”¨ sh+rdo æœç´¢å¢å¼ºç­–ç•¥\n\n\n\n\n::: {.timeline-date}2024.4 â€“ 2024.7::: ::: {.timeline-title}ç ”ç©¶åŠ©ç†ï¼ˆå¤§æ¨¡å‹æ•°æ®ï¼‰::: ::: {.timeline-org}åŒ—äº¬ç§‘å­¦é™¢æ™ºèƒ½ç ”ç©¶é™¢ | ç†”ç‚¼æµä½“å›¢é˜Ÿ:::\n\n::: {.tag}LLaMA-Factory::: ::: {.tag}LoRA::: ::: {.tag}QLoRA::: ::: {.tag}Data Pipeline:::\n\n\nè´Ÿè´£å¤§æ¨¡å‹æ•°æ® pipelineã€è®ºæ–‡ä¸æ•™ç¨‹æ•´ç†\næ„å»ºä¸€ä½“åŒ–æ•°æ®æ¸…æ´—ä¸è®­ç»ƒæµç¨‹\nåŸºäº LLaMA-Factory æ¡†æ¶ï¼Œç»“åˆ LoRA/QLoRA å¾®è°ƒ Qwen1.4B æ¨¡å‹"
  },
  {
    "objectID": "Chinese.html#é¡¹ç›®ç»å†",
    "href": "Chinese.html#é¡¹ç›®ç»å†",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "é¡¹ç›®ç»å†",
    "text": "é¡¹ç›®ç»å†\n\n\nWebAgent å¼ºåŒ–å­¦ä¹ å¢å¼º VLM\n\n::: {.tag}VLM::: ::: {.tag}RL::: ::: {.tag}WebAgent:::\n\nä¸é¦™æ¸¯å¤§å­¦åˆä½œ (2025.4 â€“ 2025.6)\n\nKnow-RFT æ¡†æ¶ï¼š é’ˆå¯¹ VLM äº‹å®çŸ¥è¯†ä¸è¶³é—®é¢˜ï¼Œè®¾è®¡ instruction-aware SFT ä¸ Web-Agent å¢å¼ºå­¦ä¹ \nKnow-RFT-3Bï¼š åœ¨æœ‰é™æ˜¾å­˜ç¯å¢ƒä¸‹å®ç°å¢é‡è®­ç»ƒä¸æ£€ç´¢å¢å¼º\næŠ€æœ¯æ ˆï¼š RAGã€Search-R1 ç»“åˆ\n\n\n\näºŒç»´ç‡ƒçƒ§åœºç ”ç©¶\n\n::: {.tag}CNN::: ::: {.tag}Transformer::: ::: {.tag}Diffusion Model::: ::: {.tag}PINN:::\n\nä¸è“ç®­èˆªå¤©åˆä½œ (2024.11 â€“ 2025.3)\n\nVIT-UNetï¼š å»ºæ¨¡ç«ç„°å›¾åƒï¼ŒRMSE â‰ˆ 0.65%\nç‰©ç†é‡é‡å»ºï¼š ç»“åˆå¯†åº¦/æ¸©åº¦åœºæ•°æ®ï¼Œè”åˆ CNN+Transformer è¿›è¡Œå›å½’\nç‰©ç†çº¦æŸï¼š å°è¯•æ‰©æ•£æ¨¡å‹ + PINN æå‡ç¨³å®šæ€§"
  },
  {
    "objectID": "Chinese.html#è£èª‰å¥–åŠ±",
    "href": "Chinese.html#è£èª‰å¥–åŠ±",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "è£èª‰å¥–åŠ±",
    "text": "è£èª‰å¥–åŠ±\n\n\n::: {.tag}2024.09:::\n\n\n2024å¹´\n\nåŒ—äº¬å¤§å­¦ä¸‰å¥½å­¦ç”Ÿ\nåŒ—äº¬å¤§å­¦ç§‘å­¦å­¦é™¢å®è·µåˆ›æ–°å¥–\n\n\n::: {.tag}2023.10:::\n\n\n\n2023å¹´\n\nå…ˆå¯¼è®¡ç®—æœºæœºæˆ¿å¤§èµ›ä¸­å—èµ›åŒºä¸€ç­‰å¥–\n\n\n::: {.tag}2021.10:::\n\n\n\n2021å¹´\n\nå­¦æœ¯/ç§‘åˆ›ä¸ªäººè¯„ä¼˜ä¸‰ç­‰å¥–å­¦é‡‘\n\n\n::: {.tag}2020.09:::\n\n\n\n2020å¹´\n\nä¸­å—å¤§å­¦ä¼˜ç§€å­¦ç”Ÿå¹²éƒ¨\nä¸‰å¥½å­¦ç”Ÿç­‰å¤šé¡¹å¥–å­¦é‡‘"
  },
  {
    "objectID": "Chinese.html#ä¸‹è½½å®Œæ•´ç®€å†",
    "href": "Chinese.html#ä¸‹è½½å®Œæ•´ç®€å†",
    "title": "ä¸­æ–‡ç®€å†",
    "section": "ä¸‹è½½å®Œæ•´ç®€å†",
    "text": "ä¸‹è½½å®Œæ•´ç®€å†\n\nğŸ“„ ç‚¹å‡»ä¸‹è½½å®Œæ•´ç®€å†ï¼ˆCVï¼‰\næŸ¥çœ‹æ›´è¯¦ç»†çš„ä¸­è‹±æ–‡ç®€å†å†…å®¹"
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "CV",
    "section": "",
    "text": "â˜€ï¸\n  ğŸŒ™\n\n\n\n\n\nThis page points to the live HTML CV and profile.\n\nä¸­æ–‡ CV: Chinese.html\nHome: index.html"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Quanjia Xiao",
    "section": "ğŸ‘¤",
    "text": "ğŸ‘¤\nAbout\nLearn more about my background and experience"
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "Quanjia Xiao",
    "section": "ğŸ”¬",
    "text": "ğŸ”¬\nProjects\nExplore my research and development work"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "Quanjia Xiao",
    "section": "ğŸ“",
    "text": "ğŸ“\nCV\nDownload my full resume"
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "Quanjia Xiao",
    "section": "ğŸ“§",
    "text": "ğŸ“§\nContact\nGet in touch with me"
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Quanjia Xiao",
    "section": "Background",
    "text": "Background\n\n\nğŸ“ Education\n\n2023.9 â€“ 2026.6 Â· M.S. in Industrial Software\n\nPeking University (åŒ—äº¬å¤§å­¦)\n\n\nâ€” Ranking: 10/65\n\n2018.9 â€“ 2022.6 Â· B.S. in Computer Science and Technology\n\nCentral South University (ä¸­å—å¤§å­¦)\n\n\nâ€” GPA: 3.5/4.0\n\n\n\n\nğŸ’¼ Work Experience\n\n2022.7 â€“ 2023.6 Â· FinTech Engineer (Full-time)\n\nBank of Communications Software Center (äº¤é€šé“¶è¡Œè½¯ä»¶ä¸­å¿ƒ, Changsha)\n\n\nâ€” Backend development for internal banking systems"
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Quanjia Xiao",
    "section": "Research Interests",
    "text": "Research Interests\n\nMy research focuses on Large Language Models, Computer Vision, and AI Agents. Iâ€™m particularly interested in:\n\nVision-Language Models (VLM) and multimodal AI\nReinforcement Learning for agent systems\nWeb-based AI agents and automation\nScientific computing applications"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Quanjia Xiao",
    "section": "Contact",
    "text": "Contact\n\nFeel free to reach out if youâ€™re interested in collaboration or just want to chat!\n\nEmail: xiaoqj@stu.pku.edu.cn\nGitHub: KuroJim"
  },
  {
    "objectID": "readme.html#about-this-site",
    "href": "readme.html#about-this-site",
    "title": "Quanjia Xiao (è‚–æƒçˆ)",
    "section": "About this site",
    "text": "About this site\nThis is the Quarto source for Quanjia Xiaoâ€™s personal site at https://kurojim.github.io.\n\nSource content lives in .qmd / .md at repo root.\nBuilt site is in docs/ for GitHub Pages.\n\nQuestions or suggestions: open an issue at https://github.com/kurojim/kurojim.github.io/issues."
  }
]